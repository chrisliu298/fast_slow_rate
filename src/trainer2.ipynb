{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainer2_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3q9AOLDzgBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf fast_slow_rate/ oracle25000.tsv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_3hL8-TuSOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b2fd4bfb-94ba-44ed-e65d-ec8d4a99c022"
      },
      "source": [
        "!git clone https://github.com/chrisliu298/fast_slow_rate.git\n",
        "!cp fast_slow_rate/oracle25000.tsv ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fast_slow_rate'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 107 (delta 1), reused 2 (delta 0), pack-reused 101\u001b[K\n",
            "Receiving objects: 100% (107/107), 49.03 MiB | 13.26 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "Checking out files: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4lg4hLENfiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Dataset\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Others\n",
        "from statistics import mean\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def plot(history, string):\n",
        "    \"\"\"\n",
        "    Plot training acc/loss and validation acc/loss\n",
        "    \"\"\"\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history[\"val_\" + string])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([\"train_\" + string, \"valid_\" + string])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class GridSearch:\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_size,\n",
        "        valid_size,\n",
        "        test_size,\n",
        "        lstm_search_space,\n",
        "        dense_search_space,\n",
        "        dropout_search_space,\n",
        "        batch_size,\n",
        "        learning_rate,\n",
        "    ):\n",
        "        # Parameters\n",
        "        self.train_size = train_size\n",
        "        self.valid_size = valid_size\n",
        "        self.test_size = test_size\n",
        "        self.lstm_search_space = lstm_search_space\n",
        "        self.dense_search_space = dense_search_space\n",
        "        self.dropout_search_space = dropout_search_space\n",
        "        self.vocab_size = 20000\n",
        "        self.embedding_dim = 50\n",
        "        self.max_len = 512\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = 50\n",
        "        self.patience = 10\n",
        "        self.seed = 42\n",
        "        self.trunc_type = \"post\"\n",
        "        self.padding = \"pre\"\n",
        "        self.oov_token = \"<OOV>\"\n",
        "        self.callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor=\"val_accuracy\",\n",
        "                patience=self.patience,\n",
        "                restore_best_weights=True,\n",
        "            )\n",
        "        ]\n",
        "        # Load the dataset\n",
        "        imdb = tfds.load(\"imdb_reviews\", as_supervised=True, shuffle_files=True)\n",
        "        oracle_train = pd.read_csv(\"oracle25000.tsv\", delimiter=\"\\t\")\n",
        "        self.oracle_text = oracle_train[\"reviews\"]\n",
        "        self.oracle_labels = oracle_train[\"oracle_labels\"]\n",
        "        self.train_dataset = imdb[\"train\"]\n",
        "        self.test_dataset = imdb[\"test\"]\n",
        "\n",
        "    def prepare_data(self):\n",
        "        train_text = self.oracle_text\n",
        "        train_labels = self.oracle_labels\n",
        "        test_text = []\n",
        "        test_labels = []\n",
        "\n",
        "        # Put sentences and labels in lists\n",
        "        for s, l in self.test_dataset:\n",
        "            test_text.append(str(s.numpy()))\n",
        "            test_labels.append(l.numpy())\n",
        "\n",
        "        # Convert them into numpy arrays\n",
        "        train_text, train_labels, test_text, test_labels = (\n",
        "            np.array(train_text),\n",
        "            np.array(train_labels),\n",
        "            np.array(test_text),\n",
        "            np.array(test_labels),\n",
        "        )\n",
        "\n",
        "        # Shuffle the train/test set\n",
        "        train_rand = np.arange(len(train_text))\n",
        "        np.random.shuffle(train_rand)\n",
        "        train_text = train_text[train_rand]\n",
        "        train_labels = train_labels[train_rand]\n",
        "        \n",
        "        test_rand = np.arange(len(test_text))\n",
        "        np.random.shuffle(test_rand)\n",
        "        test_text = test_text[test_rand]\n",
        "        test_labels = test_labels[test_rand]\n",
        "\n",
        "        # Take the subset of the data\n",
        "        train_reviews, valid_reviews = (\n",
        "            train_text[: self.train_size],\n",
        "            train_text[-self.valid_size :],\n",
        "        )\n",
        "        train_sentiments, valid_sentiments = (\n",
        "            np.array(train_labels[: self.train_size]),\n",
        "            np.array(train_labels[-self.valid_size :]),\n",
        "        )\n",
        "        test_reviews = test_text[: self.test_size]\n",
        "        test_sentiments = np.array(test_labels[: self.test_size])\n",
        "\n",
        "        tokenizer = Tokenizer(num_words=self.vocab_size, oov_token=self.oov_token)\n",
        "        tokenizer.fit_on_texts(train_reviews)\n",
        "\n",
        "        train_seq = tokenizer.texts_to_sequences(train_reviews)\n",
        "        train_padded = pad_sequences(\n",
        "            train_seq,\n",
        "            maxlen=self.max_len,\n",
        "            truncating=self.trunc_type,\n",
        "            padding=self.padding,\n",
        "        )\n",
        "        valid_seq = tokenizer.texts_to_sequences(valid_reviews)\n",
        "        valid_padded = pad_sequences(\n",
        "            valid_seq,\n",
        "            maxlen=self.max_len,\n",
        "            truncating=self.trunc_type,\n",
        "            padding=self.padding,\n",
        "        )\n",
        "        test_seq = tokenizer.texts_to_sequences(test_reviews)\n",
        "        test_padded = pad_sequences(\n",
        "            test_seq,\n",
        "            maxlen=self.max_len,\n",
        "            truncating=self.trunc_type,\n",
        "            padding=self.padding,\n",
        "        )\n",
        "\n",
        "        print(\"Training sentences count:\", len(train_padded))\n",
        "        print(\"Training labels count:\", len(train_sentiments))\n",
        "        print(\"Validation sentences count:\", len(valid_padded))\n",
        "        print(\"Validation labels count:\", len(valid_sentiments))\n",
        "        print(\"Test sentences count:\", len(test_padded))\n",
        "        print(\"Testing labels count:\", len(test_sentiments))\n",
        "        print()\n",
        "        return [\n",
        "            (train_padded, train_sentiments),\n",
        "            (valid_padded, valid_sentiments),\n",
        "            (test_padded, test_sentiments),\n",
        "        ]\n",
        "\n",
        "    def build_model(self, lstm_hidden_size, dense_hidden_size, dropout_rate):\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            Embedding(self.vocab_size, self.embedding_dim, input_length=self.max_len)\n",
        "        )\n",
        "        model.add(Bidirectional(LSTM(lstm_hidden_size, return_sequences=True)))\n",
        "        model.add(GlobalMaxPool1D())\n",
        "        model.add(Dense(dense_hidden_size, activation=\"relu\"))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "        model.add(Dense(1, activation=\"sigmoid\"))\n",
        "        model.compile(\n",
        "            loss=\"binary_crossentropy\",\n",
        "            optimizer=Adam(learning_rate=self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def train(self, data):\n",
        "        (\n",
        "            (train_padded, train_sentiments),\n",
        "            (valid_padded, valid_sentiments),\n",
        "            (test_padded, test_sentiments),\n",
        "        ) = data\n",
        "        histories = []\n",
        "        counter = 0\n",
        "        for lstm_size in self.lstm_search_space:\n",
        "            for dense_size in self.dense_search_space:\n",
        "                for dropout_rate in self.dropout_search_space:\n",
        "                    model = self.build_model(lstm_size, dense_size, dropout_rate)\n",
        "                    counter += 1\n",
        "                    print(f\"========== Trial {counter} Summary ==========\")\n",
        "                    print(f\"   lstm_search_space = {lstm_size}\")\n",
        "                    print(f\"  dense_search_space = {dense_size}\")\n",
        "                    print(f\"dropout_search_space = {dropout_rate}\\n\")\n",
        "                    history = model.fit(\n",
        "                        train_padded,\n",
        "                        train_sentiments,\n",
        "                        validation_data=(valid_padded, valid_sentiments),\n",
        "                        batch_size=self.batch_size,\n",
        "                        epochs=self.epochs,\n",
        "                        shuffle=True,\n",
        "                        callbacks=self.callbacks,\n",
        "                        verbose=0\n",
        "                    )\n",
        "                    log = {\n",
        "                        \"lstm_hidden_size\": lstm_size,\n",
        "                        \"dense_hidden_size\": dense_size,\n",
        "                        \"dropout_rate\": dropout_rate,\n",
        "                        \"train_acc_early_stop\": history.history[\"accuracy\"][-11],\n",
        "                        \"train_acc_final\": history.history[\"accuracy\"][-1],\n",
        "                        \"valid_acc_early_stop\": history.history[\"val_accuracy\"][-11],\n",
        "                        \"valid_acc_final\": history.history[\"val_accuracy\"][-1],\n",
        "                        \"max_valid_acc\": max(history.history[\"val_accuracy\"]),\n",
        "                    }\n",
        "                    histories.append(log)\n",
        "                    print()\n",
        "                    print(f\"========== Trial {counter} Results ==========\")\n",
        "                    print(json.dumps(log, indent=4))\n",
        "                    print()\n",
        "        return histories\n",
        "\n",
        "    def get_best_model(self, history):\n",
        "        return max(history, key=lambda x: x[\"max_valid_acc\"])\n",
        "\n",
        "    def train_best_model(self, best_params, num_trials=100):\n",
        "        best_lstm_size = best_params[\"lstm_hidden_size\"]\n",
        "        best_dense_size = best_params[\"dense_hidden_size\"]\n",
        "        best_dropout_rate = best_params[\"dropout_rate\"]\n",
        "        (train_padded, train_sentiments), (valid_padded, valid_sentiments), (test_padded, test_sentiments) = self.prepare_data()\n",
        "        train_acc = []\n",
        "        final_train_acc = []\n",
        "        valid_acc = []\n",
        "        final_valid_acc = []\n",
        "        test_acc = []\n",
        "        for t in range(num_trials):\n",
        "            print(f\"========== Tiral {t + 1} ==========\")\n",
        "            model = self.build_model(best_lstm_size, best_dense_size, best_dropout_rate)\n",
        "            history = model.fit(\n",
        "                train_padded,\n",
        "                train_sentiments,\n",
        "                validation_data=(valid_padded, valid_sentiments),\n",
        "                batch_size=self.batch_size,\n",
        "                epochs=self.epochs,\n",
        "                shuffle=True,\n",
        "                callbacks=self.callbacks,\n",
        "                verbose=0\n",
        "            )\n",
        "            loss, acc = model.evaluate(test_padded, test_sentiments, batch_size=self.batch_size)\n",
        "            train_acc.append(history.history[\"accuracy\"][-11])\n",
        "            final_train_acc.append(history.history[\"accuracy\"][-1])\n",
        "            valid_acc.append(history.history[\"val_accuracy\"][-11])\n",
        "            final_valid_acc.append(history.history[\"val_accuracy\"][-1])\n",
        "            test_acc.append(acc)\n",
        "            print()\n",
        "        return (train_acc, final_train_acc, valid_acc, final_valid_acc, test_acc)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VsAwqFeEep2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "b47b078c-10af-423c-fbea-b0dbb95034b2"
      },
      "source": [
        "start = timer()\n",
        "search = GridSearch(\n",
        "    train_size=3000,\n",
        "    valid_size=2000,\n",
        "    test_size=12500,\n",
        "    lstm_search_space=[16],\n",
        "    dense_search_space=[256],\n",
        "    dropout_search_space=[0.1],\n",
        "    batch_size=32,\n",
        "    learning_rate=3e-4,\n",
        ")\n",
        "\n",
        "data = search.prepare_data()\n",
        "history = search.train(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sentences count: 3000\n",
            "Training labels count: 3000\n",
            "Validation sentences count: 2000\n",
            "Validation labels count: 2000\n",
            "Test sentences count: 12500\n",
            "Testing labels count: 12500\n",
            "\n",
            "========== Trial 1 Summary ==========\n",
            "   lstm_search_space = 16\n",
            "  dense_search_space = 256\n",
            "dropout_search_space = 0.1\n",
            "\n",
            "\n",
            "========== Trial 1 Results ==========\n",
            "{\n",
            "    \"lstm_hidden_size\": 16,\n",
            "    \"dense_hidden_size\": 256,\n",
            "    \"dropout_rate\": 0.1,\n",
            "    \"train_acc_early_stop\": 0.9576666951179504,\n",
            "    \"train_acc_final\": 0.999666690826416,\n",
            "    \"valid_acc_early_stop\": 0.8565000295639038,\n",
            "    \"valid_acc_final\": 0.8295000195503235,\n",
            "    \"max_valid_acc\": 0.8565000295639038\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvqa0vbcPicb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7dfca536-4798-43c1-e77e-1c74bd5463cb"
      },
      "source": [
        "best_params = search.get_best_model(history)\n",
        "print(json.dumps(best_params, indent=4))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"lstm_hidden_size\": 16,\n",
            "    \"dense_hidden_size\": 256,\n",
            "    \"dropout_rate\": 0.1,\n",
            "    \"train_acc_early_stop\": 0.9576666951179504,\n",
            "    \"train_acc_final\": 0.999666690826416,\n",
            "    \"valid_acc_early_stop\": 0.8565000295639038,\n",
            "    \"valid_acc_final\": 0.8295000195503235,\n",
            "    \"max_valid_acc\": 0.8565000295639038\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApYezz9Yur6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34f6baab-6803-43a3-937b-85bc5b05ad77"
      },
      "source": [
        "(train_acc, final_train_acc, valid_acc, final_valid_acc, test_acc) = search.train_best_model(best_params)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sentences count: 3000\n",
            "Training labels count: 3000\n",
            "Validation sentences count: 2000\n",
            "Validation labels count: 2000\n",
            "Test sentences count: 12500\n",
            "Testing labels count: 12500\n",
            "\n",
            "========== Tiral 1 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4414 - accuracy: 0.8403\n",
            "\n",
            "========== Tiral 2 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.3960 - accuracy: 0.8339\n",
            "\n",
            "========== Tiral 3 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5179 - accuracy: 0.8450\n",
            "\n",
            "========== Tiral 4 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6475 - accuracy: 0.8350\n",
            "\n",
            "========== Tiral 5 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4875 - accuracy: 0.8386\n",
            "\n",
            "========== Tiral 6 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.7290 - accuracy: 0.8284\n",
            "\n",
            "========== Tiral 7 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4750 - accuracy: 0.8458\n",
            "\n",
            "========== Tiral 8 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4585 - accuracy: 0.8482\n",
            "\n",
            "========== Tiral 9 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.7337 - accuracy: 0.8335\n",
            "\n",
            "========== Tiral 10 ==========\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.5293 - accuracy: 0.8450\n",
            "\n",
            "========== Tiral 11 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4061 - accuracy: 0.8505\n",
            "\n",
            "========== Tiral 12 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.5803 - accuracy: 0.8401\n",
            "\n",
            "========== Tiral 13 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6200 - accuracy: 0.8378\n",
            "\n",
            "========== Tiral 14 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5339 - accuracy: 0.8482\n",
            "\n",
            "========== Tiral 15 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.7837 - accuracy: 0.8381\n",
            "\n",
            "========== Tiral 16 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4229 - accuracy: 0.8328\n",
            "\n",
            "========== Tiral 17 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6214 - accuracy: 0.8253\n",
            "\n",
            "========== Tiral 18 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.5358 - accuracy: 0.8379\n",
            "\n",
            "========== Tiral 19 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4495 - accuracy: 0.8476\n",
            "\n",
            "========== Tiral 20 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4582 - accuracy: 0.8378\n",
            "\n",
            "========== Tiral 21 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6014 - accuracy: 0.8467\n",
            "\n",
            "========== Tiral 22 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5325 - accuracy: 0.8331\n",
            "\n",
            "========== Tiral 23 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5422 - accuracy: 0.8346\n",
            "\n",
            "========== Tiral 24 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6334 - accuracy: 0.8342\n",
            "\n",
            "========== Tiral 25 ==========\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.5878 - accuracy: 0.8366\n",
            "\n",
            "========== Tiral 26 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4183 - accuracy: 0.8426\n",
            "\n",
            "========== Tiral 27 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6154 - accuracy: 0.8406\n",
            "\n",
            "========== Tiral 28 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.5076 - accuracy: 0.8442\n",
            "\n",
            "========== Tiral 29 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5729 - accuracy: 0.8377\n",
            "\n",
            "========== Tiral 30 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4603 - accuracy: 0.8413\n",
            "\n",
            "========== Tiral 31 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.6868 - accuracy: 0.8334\n",
            "\n",
            "========== Tiral 32 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4482 - accuracy: 0.8344\n",
            "\n",
            "========== Tiral 33 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.6300 - accuracy: 0.8400\n",
            "\n",
            "========== Tiral 34 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.9540 - accuracy: 0.8254\n",
            "\n",
            "========== Tiral 35 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.6376 - accuracy: 0.8470\n",
            "\n",
            "========== Tiral 36 ==========\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.6078 - accuracy: 0.8245\n",
            "\n",
            "========== Tiral 37 ==========\n",
            "391/391 [==============================] - 8s 20ms/step - loss: 0.5694 - accuracy: 0.8420\n",
            "\n",
            "========== Tiral 38 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.5421 - accuracy: 0.8414\n",
            "\n",
            "========== Tiral 39 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.5211 - accuracy: 0.8489\n",
            "\n",
            "========== Tiral 40 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4544 - accuracy: 0.8482\n",
            "\n",
            "========== Tiral 41 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7210 - accuracy: 0.8389\n",
            "\n",
            "========== Tiral 42 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6284 - accuracy: 0.8447\n",
            "\n",
            "========== Tiral 43 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4460 - accuracy: 0.8424\n",
            "\n",
            "========== Tiral 44 ==========\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.4233 - accuracy: 0.8310\n",
            "\n",
            "========== Tiral 45 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4536 - accuracy: 0.8468\n",
            "\n",
            "========== Tiral 46 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5788 - accuracy: 0.8379\n",
            "\n",
            "========== Tiral 47 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5314 - accuracy: 0.8335\n",
            "\n",
            "========== Tiral 48 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4935 - accuracy: 0.8407\n",
            "\n",
            "========== Tiral 49 ==========\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.5208 - accuracy: 0.8412\n",
            "\n",
            "========== Tiral 50 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5032 - accuracy: 0.8446\n",
            "\n",
            "========== Tiral 51 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4526 - accuracy: 0.8418\n",
            "\n",
            "========== Tiral 52 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5284 - accuracy: 0.8418\n",
            "\n",
            "========== Tiral 53 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5200 - accuracy: 0.8377\n",
            "\n",
            "========== Tiral 54 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5718 - accuracy: 0.8232\n",
            "\n",
            "========== Tiral 55 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6492 - accuracy: 0.8317\n",
            "\n",
            "========== Tiral 56 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3828 - accuracy: 0.8427\n",
            "\n",
            "========== Tiral 57 ==========\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.4529 - accuracy: 0.8464\n",
            "\n",
            "========== Tiral 58 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6254 - accuracy: 0.8352\n",
            "\n",
            "========== Tiral 59 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7184 - accuracy: 0.8277\n",
            "\n",
            "========== Tiral 60 ==========\n",
            "391/391 [==============================] - 8s 19ms/step - loss: 0.4965 - accuracy: 0.8459\n",
            "\n",
            "========== Tiral 61 ==========\n",
            "391/391 [==============================] - 7s 19ms/step - loss: 0.4629 - accuracy: 0.8449\n",
            "\n",
            "========== Tiral 62 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6850 - accuracy: 0.8358\n",
            "\n",
            "========== Tiral 63 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5358 - accuracy: 0.8204\n",
            "\n",
            "========== Tiral 64 ==========\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.4828 - accuracy: 0.8412\n",
            "\n",
            "========== Tiral 65 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4499 - accuracy: 0.8400\n",
            "\n",
            "========== Tiral 66 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6498 - accuracy: 0.8328\n",
            "\n",
            "========== Tiral 67 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5128 - accuracy: 0.8446\n",
            "\n",
            "========== Tiral 68 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5695 - accuracy: 0.8391\n",
            "\n",
            "========== Tiral 69 ==========\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.3847 - accuracy: 0.8406\n",
            "\n",
            "========== Tiral 70 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5529 - accuracy: 0.8409\n",
            "\n",
            "========== Tiral 71 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7174 - accuracy: 0.8342\n",
            "\n",
            "========== Tiral 72 ==========\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.5543 - accuracy: 0.8288\n",
            "\n",
            "========== Tiral 73 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5370 - accuracy: 0.8440\n",
            "\n",
            "========== Tiral 74 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5139 - accuracy: 0.8362\n",
            "\n",
            "========== Tiral 75 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5778 - accuracy: 0.8366\n",
            "\n",
            "========== Tiral 76 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4838 - accuracy: 0.8438\n",
            "\n",
            "========== Tiral 77 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5608 - accuracy: 0.8478\n",
            "\n",
            "========== Tiral 78 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6032 - accuracy: 0.8318\n",
            "\n",
            "========== Tiral 79 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6530 - accuracy: 0.8377\n",
            "\n",
            "========== Tiral 80 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4064 - accuracy: 0.8421\n",
            "\n",
            "========== Tiral 81 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3815 - accuracy: 0.8424\n",
            "\n",
            "========== Tiral 82 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4139 - accuracy: 0.8446\n",
            "\n",
            "========== Tiral 83 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6551 - accuracy: 0.8480\n",
            "\n",
            "========== Tiral 84 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7431 - accuracy: 0.8311\n",
            "\n",
            "========== Tiral 85 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5421 - accuracy: 0.8027\n",
            "\n",
            "========== Tiral 86 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7300 - accuracy: 0.8365\n",
            "\n",
            "========== Tiral 87 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4598 - accuracy: 0.8456\n",
            "\n",
            "========== Tiral 88 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5017 - accuracy: 0.8468\n",
            "\n",
            "========== Tiral 89 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4802 - accuracy: 0.8410\n",
            "\n",
            "========== Tiral 90 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5187 - accuracy: 0.8421\n",
            "\n",
            "========== Tiral 91 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5320 - accuracy: 0.8361\n",
            "\n",
            "========== Tiral 92 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4633 - accuracy: 0.8454\n",
            "\n",
            "========== Tiral 93 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5093 - accuracy: 0.8241\n",
            "\n",
            "========== Tiral 94 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5020 - accuracy: 0.8414\n",
            "\n",
            "========== Tiral 95 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4140 - accuracy: 0.8399\n",
            "\n",
            "========== Tiral 96 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6688 - accuracy: 0.8462\n",
            "\n",
            "========== Tiral 97 ==========\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.4919 - accuracy: 0.8447\n",
            "\n",
            "========== Tiral 98 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4518 - accuracy: 0.8389\n",
            "\n",
            "========== Tiral 99 ==========\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.5506 - accuracy: 0.8394\n",
            "\n",
            "========== Tiral 100 ==========\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7261 - accuracy: 0.8237\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_BDD3Xv1mhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statistics import mean"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIk4SQtw1nqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "428a5605-fdeb-4e6c-d53c-f6a9705e8a3c"
      },
      "source": [
        "print(search.train_size)\n",
        "print(round(mean(train_acc), 4))\n",
        "print(round(mean(final_train_acc), 4))\n",
        "print(round(mean(valid_acc), 4))\n",
        "print(round(mean(final_valid_acc), 4))\n",
        "print(round(mean(test_acc), 4))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "0.9919\n",
            "0.9993\n",
            "0.8767\n",
            "0.8596\n",
            "0.8387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arI04qAy2C0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "381e8e1c-d627-4a18-a0a3-780db09b60c9"
      },
      "source": [
        "end = timer()\n",
        "print((end - start) / 3600)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.9824786226005564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqgpdPrT_hWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}